---
layout: post
title: "Predicting Flight Delays"
subtitle: "A Data Analysis and Modeling Project Using R"
date:       2022-12-10 12:00:00
author: "Yingqian Cao"
header-style: text
catalog:      true
tags:
  - CMU
  - R
---

## Introduction

As part of the statistics curriculum at Carnegie Mellon University (CMU), my team and 
I conducted an in-depth analysis of U.S. domestic [flight delay data from December 2016]
(http://rosmarus.refsmmat.com/datasets/datasets/ﬂight-delays/
) using R. 
Flight delays are a common issue in the aviation industry, affecting millions of passengers annually 
and causing significant economic losses. Our goal was to develop a predictive model that could 
accurately forecast flight arrival delay times (ARR_DELAY).
![](/img/36600_poster.pdf)


## Data Preparation and Exploratory Analysis

We obtained the raw dataset from the U.S. Bureau of Transportation Statistics,
containing 34,314 flight records from December 2016, specifically focusing on flights between 
Chicago O'Hare (ORD) and Dallas-Fort Worth (DFW) airports.

### Data Cleaning Steps:
Removed variables deterministically related to the response variable (e.g., specific delay reasons)  
Applied logarithmic transformations to skewed variables (e.g., TAXI_IN and TAXI_OUT)  
Filtered outliers (e.g., flights with ARR_DELAY>120 minutes or DEP_DELAY>100 minutes)  
Retained 12 predictor variables including airline (CARRIER), origin (ORIGIN), destination (DEST), departure delay (DEP_DELAY), etc.  
```ts
# Data cleaning code example
df.new <- df.combine %>% 
  filter(ACTUAL_ELAPSED_TIME<400) %>% 
  filter(ARR_TIME>500) %>% 
  filter(ARR_DELAY<120) %>% 
  filter(DEP_DELAY<100) %>% 
  filter(DEP_DELAY > -20)
```

## Modeling Approach
We split the data into 70% training and 30% test sets, comparing five different regression models:  
**Linear Regression:** Baseline model  
**Decision Tree:** Interpretable but prone to overfitting  
**Random Forest:** Handles high-dimensional data well  
**Extreme Gradient Boosting (XGBoost):** Ensemble learning method  
**K-Nearest Neighbors (KNN):** Similarity-based non-parametric approach  
We used Mean Squared Error (MSE) as our evaluation metric and employed the bestglm package for variable selection:  
```ts
# Selecting the best model using BIC criterion
bg.outB <- bestglm(df.train, family=gaussian, IC="BIC")
summary(bg.outB$BestModel)$adj.r.squared  # Achieved 0.971 adjusted R-squared
```


## Key Findings

### Variable Importance:  
Departure delay (DEP_DELAY) was the most significant predictor  
Taxi-out time (TAXI_OUT) and airline (CARRIER) also had notable impact

### Model Comparison:  
Linear regression and random forest performed best (MSE≈57-73)  
KNN performed worst (MSE=128.47), partly due to its inability to handle categorical variables effectively  
Decision trees tended to overfit, showing poor test performance (MSE=103.458)  

### BIC vs AIC:   
BIC selected a more parsimonious model (1 variable)  
AIC selected a more complex model (6 variables)  
This validated the theory that BIC prevents overfitting while AIC tends to fit data better  


## Visual Analysis

We created several key visualizations to understand the data:  
**Variable distribution histograms:** Showed most flight delays concentrated in 0-30 minutes  
**Correlation matrix:** Revealed high correlation between ARR_DELAY and DEP_DELAY (r≈0.9)  
**BIC curve plot:** Helped determine optimal model complexity  
```ts
# BIC curve plotting code
ggplot(data=df.bic, mapping=aes(x=p,y=BIC)) + 
  geom_point(size=1.5,color="blue") + 
  geom_line(color="blue") +
  ylim(min(bic),min(bic+100))
```

## Challenges and Solutions
**Categorical Variable Handling:**  
Random forest limited factors to 53 levels per column, forcing removal of destination (DEST) variable  
Solution: Consider encoding destinations as geographic regions rather than specific airports  
**Fair Model Comparison:**  
Ensured all models used the same variable set for fair comparison  
Linear regression remained robust even after removing DEST variable  
**Computational Efficiency:**  
Random forest and XGBoost required longer training times  
Solution: Used subsampling and parallel computing to accelerate training  


## Conclusions and Business Implications

Our analysis demonstrated that simple linear regression performed exceptionally well in predicting flight delays, achieving an adjusted R² of 0.971. These findings have practical significance:  

**Airline Operations:** Can proactively allocate resources to handle potential large-scale delays  
**Passenger Services:** Airports can provide more accurate delay information to improve passenger experience  
**Cost Control:** Reduce additional operational costs caused by delays  

Future work could explore:  
Encoding destinations as geographic coordinates or regions  
Incorporating external variables like weather data  
Developing real-time prediction systems  

This project not only deepened my understanding of statistical modeling but also showcased R's powerful capabilities in data science projects—from data cleaning to advanced modeling and result visualization, the R ecosystem provides a complete solution.

